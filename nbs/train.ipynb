{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4e91f0-dfee-4752-8314-a6eff146505f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding=utf-8\n",
    "# Copyright 2021 The HuggingFace Team All rights reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\"\"\"\n",
    "Pre-training/Fine-tuning the library models for causal language modeling (GPT, GPT-2, CTRL, ...) on a text file or a dataset.\n",
    "\n",
    "Here is the full list of checkpoints on the hub that can be fine-tuned by this script:\n",
    "https://huggingface.co/models?filter=causal-lm\n",
    "\"\"\"\n",
    "# You can also adapt this script on your own causal language modeling task. Pointers for this are left as comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64174c3c-1ca5-4978-88d7-b2c241eddd69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import math\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "from dataclasses import dataclass, field\n",
    "from pathlib import Path\n",
    "from typing import Callable, Optional\n",
    "\n",
    "import datasets\n",
    "# import torch\n",
    "from datasets import Dataset, load_dataset\n",
    "from PIL import Image\n",
    "# from torchvision.io import ImageReadMode, read_image\n",
    "# from torchvision.transforms import CenterCrop, Compose, ConvertImageDtype, Normalize, Resize, ToTensor\n",
    "# from torchvision.transforms.functional import InterpolationMode\n",
    "from tqdm import tqdm\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import optax\n",
    "import transformers\n",
    "from flax import jax_utils\n",
    "from flax import linen as nn\n",
    "from flax import traverse_util\n",
    "from flax.jax_utils import prefetch_to_device, unreplicate\n",
    "from flax.training import train_state\n",
    "from flax.training.common_utils import get_metrics, onehot, shard, shard_prng_key\n",
    "from transformers import (\n",
    "    CONFIG_MAPPING,\n",
    "    FLAX_MODEL_FOR_CAUSAL_LM_MAPPING,\n",
    "    AutoConfig,\n",
    "    CLIPProcessor,\n",
    "    FlaxCLIPModel,\n",
    "    HfArgumentParser,\n",
    "    TrainingArguments,\n",
    "    is_tensorboard_available,\n",
    ")\n",
    "from transformers.testing_utils import CaptureLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfc0671-cf00-4de9-89c3-2f4ba69e503a",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Cache the result\n",
    "has_tensorboard = is_tensorboard_available()\n",
    "if has_tensorboard:\n",
    "    try:\n",
    "        from flax.metrics.tensorboard import SummaryWriter\n",
    "    except ImportError as ie:\n",
    "        has_tensorboard = False\n",
    "        print(f\"Unable to display metrics through TensorBoard because some package are not installed: {ie}\")\n",
    "\n",
    "else:\n",
    "    print(\n",
    "        \"Unable to display metrics through TensorBoard because the package is not installed: \"\n",
    "        \"Please run pip install tensorboard to enable.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbf19ea-ffad-45f3-b2e4-514bda2dfec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ModelArguments:\n",
    "    \"\"\"\n",
    "    Arguments pertaining to which model/config/tokenizer we are going to fine-tune, or train from scratch.\n",
    "    \"\"\"\n",
    "\n",
    "    model_name_or_path: Optional[str] = field(\n",
    "        default=None,\n",
    "        metadata={\n",
    "            \"help\": \"The model checkpoint for weights initialization.\"\n",
    "            \"Don't set if you want to train a model from scratch.\"\n",
    "        },\n",
    "    )\n",
    "    model_type: Optional[str] = field(\n",
    "        default=None,\n",
    "        metadata={\"help\": \"If training from scratch, pass a model type from the list: [clip]\"},\n",
    "    )\n",
    "    config_name: Optional[str] = field(\n",
    "        default=None, metadata={\"help\": \"Pretrained config name or path if not the same as model_name\"}\n",
    "    )\n",
    "    tokenizer_name: Optional[str] = field(\n",
    "        default=None, metadata={\"help\": \"Pretrained tokenizer name or path if not the same as model_name\"}\n",
    "    )\n",
    "    cache_dir: Optional[str] = field(\n",
    "        default=None, metadata={\"help\": \"Where do you want to store the pretrained models downloaded from s3\"}\n",
    "    )\n",
    "    use_fast_tokenizer: bool = field(\n",
    "        default=True,\n",
    "        metadata={\"help\": \"Whether to use one of the fast tokenizer (backed by the tokenizers library) or not.\"},\n",
    "    )\n",
    "    dtype: Optional[str] = field(\n",
    "        default=\"float32\",\n",
    "        metadata={\n",
    "            \"help\": \"Floating-point format in which the model weights should be initialized and trained. Choose one of `[float32, float16, bfloat16]`.\"\n",
    "        },\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c56097-98a5-4e17-92f6-3c96aa3df60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class DataTrainingArguments:\n",
    "    \"\"\"\n",
    "    Arguments pertaining to what data we are going to input our model for training and eval.\n",
    "    \"\"\"\n",
    "\n",
    "    dataset_name: Optional[str] = field(\n",
    "        default=None, metadata={\"help\": \"The name of the dataset to use (via the datasets library).\"}\n",
    "    )\n",
    "    dataset_config_name: Optional[str] = field(\n",
    "        default=None, metadata={\"help\": \"The configuration name of the dataset to use (via the datasets library).\"}\n",
    "    )\n",
    "    train_file: Optional[str] = field(default=None, metadata={\"help\": \"The input training data file (a text file).\"})\n",
    "    validation_file: Optional[str] = field(\n",
    "        default=None,\n",
    "        metadata={\"help\": \"An optional input evaluation data file to evaluate the perplexity on (a text file).\"},\n",
    "    )\n",
    "    max_seq_length: Optional[int] = field(default=72, metadata={\"help\": \"max seq length\"})\n",
    "    max_train_samples: Optional[int] = field(\n",
    "        default=None,\n",
    "        metadata={\n",
    "            \"help\": \"For debugging purposes or quicker training, truncate the number of training examples to this \"\n",
    "            \"value if set.\"\n",
    "        },\n",
    "    )\n",
    "    max_eval_samples: Optional[int] = field(\n",
    "        default=None,\n",
    "        metadata={\n",
    "            \"help\": \"For debugging purposes or quicker training, truncate the number of evaluation examples to this \"\n",
    "            \"value if set.\"\n",
    "        },\n",
    "    )\n",
    "    overwrite_cache: bool = field(\n",
    "        default=False, metadata={\"help\": \"Overwrite the cached training and evaluation sets\"}\n",
    "    )\n",
    "    validation_split_percentage: Optional[int] = field(\n",
    "        default=5,\n",
    "        metadata={\n",
    "            \"help\": \"The percentage of the train set used as validation set in case there's no validation split\"\n",
    "        },\n",
    "    )\n",
    "    block_size: Optional[int] = field(\n",
    "        default=None,\n",
    "        metadata={\n",
    "            \"help\": \"Optional input sequence length after tokenization. \"\n",
    "            \"The training dataset will be truncated in block of this size for training. \"\n",
    "            \"Default to the model max input length for single sentence inputs (take into account special tokens).\"\n",
    "        },\n",
    "    )\n",
    "    overwrite_cache: bool = field(\n",
    "        default=False, metadata={\"help\": \"Overwrite the cached training and evaluation sets\"}\n",
    "    )\n",
    "    preprocessing_num_workers: Optional[int] = field(\n",
    "        default=None,\n",
    "        metadata={\"help\": \"The number of processes to use for the preprocessing.\"},\n",
    "    )\n",
    "\n",
    "    def __post_init__(self):\n",
    "        if self.dataset_name is None and self.train_file is None and self.validation_file is None:\n",
    "            raise ValueError(\"Need either a dataset name or a training/validation file.\")\n",
    "        else:\n",
    "            if self.train_file is not None:\n",
    "                extension = self.train_file.split(\".\")[-1]\n",
    "                assert extension in [\"csv\", \"json\", \"txt\"], \"`train_file` should be a csv, a json or a txt file.\"\n",
    "            if self.validation_file is not None:\n",
    "                extension = self.validation_file.split(\".\")[-1]\n",
    "                assert extension in [\"csv\", \"json\", \"txt\"], \"`validation_file` should be a csv, a json or a txt file.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55bdc4c1-7aa4-47bd-8ddf-0dfdcf7a1f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainState(train_state.TrainState):\n",
    "    dropout_rng: jnp.ndarray\n",
    "\n",
    "    def replicate(self):\n",
    "        return jax_utils.replicate(self).replace(dropout_rng=shard_prng_key(self.dropout_rng))\n",
    "\n",
    "\n",
    "def _transform(n_px):\n",
    "    return Compose(\n",
    "        [\n",
    "            ToTensor(),\n",
    "            Resize(n_px, interpolation=InterpolationMode.BICUBIC),\n",
    "            CenterCrop(n_px),\n",
    "            Normalize((0.48145466, 0.4578275, 0.40821073), (0.26862954, 0.26130258, 0.27577711)),\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156ecbc6-9f1f-4ac5-8b10-2a42d873fd25",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transform(torch.nn.Module):\n",
    "    def __init__(self, n_px):\n",
    "        super().__init__()\n",
    "        self.transforms = torch.nn.Sequential(\n",
    "            Resize(\n",
    "                [\n",
    "                    n_px,\n",
    "                ],\n",
    "                interpolation=InterpolationMode.BICUBIC,\n",
    "            ),\n",
    "            CenterCrop(n_px),\n",
    "            ConvertImageDtype(torch.float),\n",
    "            Normalize((0.48145466, 0.4578275, 0.40821073), (0.26862954, 0.26130258, 0.27577711)),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        with torch.no_grad():\n",
    "            x = self.transforms(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b7d8a8-c23f-45c7-8fee-3ce84a559941",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loader(\n",
    "    rng: jax.random.PRNGKey, dataset: Dataset, processor: CLIPProcessor, batch_size: int, shuffle: bool = False\n",
    "):\n",
    "    \"\"\"\n",
    "    Returns batches of size `batch_size` from truncated `dataset`, sharded over all local devices.\n",
    "    Shuffle batches if `shuffle` is `True`.\n",
    "    \"\"\"\n",
    "    steps_per_epoch = len(dataset) // batch_size\n",
    "\n",
    "    if shuffle:\n",
    "        batch_idx = jax.random.permutation(rng, len(dataset))\n",
    "    else:\n",
    "        batch_idx = jnp.arange(len(dataset))\n",
    "\n",
    "    batch_idx = batch_idx[: steps_per_epoch * batch_size]  # Skip incomplete batch.\n",
    "    batch_idx = batch_idx.reshape((steps_per_epoch, batch_size))\n",
    "\n",
    "    for idx in batch_idx:\n",
    "        batch = dataset[idx]\n",
    "\n",
    "        ## read and process images here\n",
    "        images = batch.pop(\"image_path\")\n",
    "        #         images = [Image.open(image_path).convert(\"RGB\") for image_path in images]\n",
    "\n",
    "        images = [read_image(image_path, mode=ImageReadMode.RGB) for image_path in images]\n",
    "\n",
    "        if type(processor) == CLIPProcessor:\n",
    "            batch[\"pixel_values\"] = processor(images=images, return_tensors=\"jax\").pixel_values\n",
    "        else:\n",
    "            batch[\"pixel_values\"] = [processor(image).numpy() for image in images]\n",
    "\n",
    "        batch = {k: jnp.array(v) for k, v in batch.items()}\n",
    "        batch[\"pixel_values\"] = jnp.transpose(batch[\"pixel_values\"], (0, 2, 3, 1))\n",
    "\n",
    "        batch = shard(batch)\n",
    "\n",
    "        yield batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83712463-39c9-4d8c-b022-ea77310ec0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_metric(summary_writer, train_metrics, eval_metrics, train_time, step):\n",
    "    summary_writer.scalar(\"train_time\", train_time, step)\n",
    "\n",
    "    train_metrics = get_metrics(train_metrics)\n",
    "    for key, vals in train_metrics.items():\n",
    "        tag = f\"train_{key}\"\n",
    "        for i, val in enumerate(vals):\n",
    "            summary_writer.scalar(tag, val, step - len(vals) + i + 1)\n",
    "\n",
    "    for metric_name, value in eval_metrics.items():\n",
    "        summary_writer.scalar(f\"eval_{metric_name}\", value, step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233cee2f-57ea-48a2-acb1-e46a796935c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_learning_rate_fn(\n",
    "    train_ds_size: int, train_batch_size: int, num_train_epochs: int, num_warmup_steps: int, learning_rate: float\n",
    ") -> Callable[[int], jnp.array]:\n",
    "    \"\"\"Returns a linear warmup, linear_decay learning rate function.\"\"\"\n",
    "    steps_per_epoch = train_ds_size // train_batch_size\n",
    "    num_train_steps = steps_per_epoch * num_train_epochs\n",
    "    warmup_fn = optax.linear_schedule(init_value=0.0, end_value=learning_rate, transition_steps=num_warmup_steps)\n",
    "    decay_fn = optax.linear_schedule(\n",
    "        init_value=learning_rate, end_value=0, transition_steps=num_train_steps - num_warmup_steps\n",
    "    )\n",
    "    schedule_fn = optax.join_schedules(schedules=[warmup_fn, decay_fn], boundaries=[num_warmup_steps])\n",
    "    return schedule_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798e345b-437e-463e-8869-d34a650ac3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # See all possible arguments in src/transformers/training_args.py\n",
    "    # or by passing the --help flag to this script.\n",
    "    # We now keep distinct sets of args, for a cleaner separation of concerns.\n",
    "\n",
    "    parser = HfArgumentParser((ModelArguments, DataTrainingArguments, TrainingArguments))\n",
    "    if len(sys.argv) == 2 and sys.argv[1].endswith(\".json\"):\n",
    "        # If we pass only one argument to the script and it's the path to a json file,\n",
    "        # let's parse it to get our arguments.\n",
    "        model_args, data_args, training_args = parser.parse_json_file(json_file=os.path.abspath(sys.argv[1]))\n",
    "    else:\n",
    "        model_args, data_args, training_args = parser.parse_args_into_dataclasses()\n",
    "\n",
    "    if (\n",
    "        os.path.exists(training_args.output_dir)\n",
    "        and os.listdir(training_args.output_dir)\n",
    "        and training_args.do_train\n",
    "        and not training_args.overwrite_output_dir\n",
    "    ):\n",
    "        raise ValueError(\n",
    "            f\"Output directory ({training_args.output_dir}) already exists and is not empty.\"\n",
    "            \"Use --overwrite_output_dir to overcome.\"\n",
    "        )\n",
    "\n",
    "    # Make one log on every process with the configuration for debugging.\n",
    "    logging.basicConfig(\n",
    "        format=\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\",\n",
    "        datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "        level=logging.INFO,\n",
    "    )\n",
    "    # Setup logging, we only want one process per machine to log things on the screen.\n",
    "    logger.setLevel(logging.INFO if jax.process_index() == 0 else logging.ERROR)\n",
    "    if jax.process_index() == 0:\n",
    "        datasets.utils.logging.set_verbosity_warning()\n",
    "        transformers.utils.logging.set_verbosity_info()\n",
    "    else:\n",
    "        datasets.utils.logging.set_verbosity_error()\n",
    "        transformers.utils.logging.set_verbosity_error()\n",
    "\n",
    "    # Set the verbosity to info of the Transformers logger (on main process only):\n",
    "    logger.info(f\"Training/evaluation parameters {training_args}\")\n",
    "\n",
    "    #  Get the datasets: you can either provide your own CSV/JSON/TXT training and evaluation files (see below)\n",
    "    # or just provide the name of one of the public datasets available on the hub at https://huggingface.co/datasets/\n",
    "    # (the dataset will be downloaded automatically from the datasets Hub).\n",
    "    #\n",
    "    # For CSV/JSON files, this script will use the column called 'text' or the first column if no column called\n",
    "    # 'text' is found. You can easily tweak this behavior (see below).\n",
    "    #\n",
    "    # In distributed training, the load_dataset function guarantees that only one local process can concurrently\n",
    "    # download the dataset.\n",
    "    if data_args.dataset_name is not None:\n",
    "        # Downloading and loading a dataset from the hub.\n",
    "        dataset = load_dataset(\n",
    "            data_args.dataset_name, data_args.dataset_config_name, cache_dir=model_args.cache_dir, keep_in_memory=False\n",
    "        )\n",
    "\n",
    "        if \"validation\" not in dataset.keys():\n",
    "            dataset[\"validation\"] = load_dataset(\n",
    "                data_args.dataset_name,\n",
    "                data_args.dataset_config_name,\n",
    "                split=f\"train[:{data_args.validation_split_percentage}%]\",\n",
    "                cache_dir=model_args.cache_dir,\n",
    "            )\n",
    "            dataset[\"train\"] = load_dataset(\n",
    "                data_args.dataset_name,\n",
    "                data_args.dataset_config_name,\n",
    "                split=f\"train[{data_args.validation_split_percentage}%:]\",\n",
    "                cache_dir=model_args.cache_dir,\n",
    "            )\n",
    "    else:\n",
    "        data_files = {}\n",
    "        if data_args.train_file is not None:\n",
    "            data_files[\"train\"] = data_args.train_file\n",
    "        if data_args.validation_file is not None:\n",
    "            data_files[\"validation\"] = data_args.validation_file\n",
    "        extension = data_args.train_file.split(\".\")[-1]\n",
    "        if extension == \"txt\":\n",
    "            extension = \"text\"\n",
    "        dataset = load_dataset(extension, data_files=data_files, cache_dir=model_args.cache_dir)\n",
    "    # See more about loading any type of standard or custom dataset (from files, python dict, pandas DataFrame, etc) at\n",
    "\n",
    "    # Distributed training:\n",
    "    # The .from_pretrained methods guarantee that only one local process can concurrently\n",
    "    # download model & vocab.\n",
    "    if model_args.config_name:\n",
    "        config = AutoConfig.from_pretrained(model_args.config_name, cache_dir=model_args.cache_dir)\n",
    "    elif model_args.model_name_or_path:\n",
    "        config = AutoConfig.from_pretrained(model_args.model_name_or_path, cache_dir=model_args.cache_dir)\n",
    "    else:\n",
    "        config = CONFIG_MAPPING[model_args.model_type]()\n",
    "        logger.warning(\"You are instantiating a new config instance from scratch.\")\n",
    "\n",
    "    if model_args.tokenizer_name:\n",
    "        processor = CLIPProcessor.from_pretrained(\n",
    "            model_args.tokenizer_name, cache_dir=model_args.cache_dir, use_fast=model_args.use_fast_tokenizer\n",
    "        )\n",
    "    elif model_args.model_name_or_path:\n",
    "        processor = CLIPProcessor.from_pretrained(\n",
    "            model_args.model_name_or_path, cache_dir=model_args.cache_dir, use_fast=model_args.use_fast_tokenizer\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            \"You are instantiating a new tokenizer from scratch. This is not supported by this script.\"\n",
    "            \"You can do it from another script, save it, and load it from here, using --tokenizer_name.\"\n",
    "        )\n",
    "\n",
    "    if model_args.model_name_or_path:\n",
    "        model = FlaxCLIPModel.from_pretrained(\n",
    "            model_args.model_name_or_path, config=config, seed=training_args.seed, dtype=getattr(jnp, model_args.dtype)\n",
    "        )\n",
    "    else:\n",
    "        model = FlaxCLIPModel(config, seed=training_args.seed, dtype=getattr(jnp, model_args.dtype))\n",
    "\n",
    "    # Preprocessing the datasets.\n",
    "    # First we tokenize all the texts.\n",
    "    if training_args.do_train:\n",
    "        column_names = dataset[\"train\"].column_names\n",
    "    else:\n",
    "        column_names = dataset[\"validation\"].column_names\n",
    "\n",
    "    captions_per_image = 2\n",
    "\n",
    "    def tokenize_and_process(examples):\n",
    "        captions = []\n",
    "        image_paths = []\n",
    "        for all_captions, image_name in zip(examples[\"captions\"], examples[\"image_path\"]):\n",
    "            captions.extend(all_captions[:captions_per_image])\n",
    "            image_paths.extend([image_name] * captions_per_image)\n",
    "\n",
    "        outputs = processor(\n",
    "            text=captions, max_length=data_args.max_seq_length, padding=\"max_length\", return_tensors=\"np\"\n",
    "        )\n",
    "        outputs[\"image_path\"] = image_paths\n",
    "        return outputs\n",
    "\n",
    "    tokenized_datasets = dataset.map(\n",
    "        tokenize_and_process,\n",
    "        batched=True,\n",
    "        num_proc=data_args.preprocessing_num_workers,\n",
    "        remove_columns=column_names,\n",
    "        load_from_cache_file=not data_args.overwrite_cache,\n",
    "    )\n",
    "\n",
    "    if training_args.do_train:\n",
    "        if \"train\" not in tokenized_datasets:\n",
    "            raise ValueError(\"--do_train requires a train dataset\")\n",
    "        train_dataset = tokenized_datasets[\"train\"]\n",
    "        if data_args.max_train_samples is not None:\n",
    "            train_dataset = train_dataset.select(range(data_args.max_train_samples))\n",
    "\n",
    "    if training_args.do_eval:\n",
    "        if \"validation\" not in tokenized_datasets:\n",
    "            raise ValueError(\"--do_eval requires a validation dataset\")\n",
    "        eval_dataset = tokenized_datasets[\"validation\"]\n",
    "        if data_args.max_eval_samples is not None:\n",
    "            eval_dataset = eval_dataset.select(range(data_args.max_eval_samples))\n",
    "\n",
    "    # Enable tensorboard only on the master node\n",
    "    if has_tensorboard and jax.process_index() == 0:\n",
    "        summary_writer = SummaryWriter(log_dir=Path(training_args.output_dir).joinpath(\"logs\").as_posix())\n",
    "\n",
    "    # Initialize our training\n",
    "    rng = jax.random.PRNGKey(training_args.seed)\n",
    "    rng, dropout_rng = jax.random.split(rng)\n",
    "\n",
    "    # Store some constant\n",
    "    num_epochs = int(training_args.num_train_epochs)\n",
    "    train_batch_size = int(training_args.per_device_train_batch_size) * jax.device_count()\n",
    "    eval_batch_size = int(training_args.per_device_eval_batch_size) * jax.device_count()\n",
    "    steps_per_epoch = len(train_dataset) // train_batch_size\n",
    "    total_train_steps = steps_per_epoch * num_epochs\n",
    "\n",
    "    # Create learning rate schedule\n",
    "    linear_decay_lr_schedule_fn = create_learning_rate_fn(\n",
    "        len(train_dataset),\n",
    "        train_batch_size,\n",
    "        training_args.num_train_epochs,\n",
    "        training_args.warmup_steps,\n",
    "        training_args.learning_rate,\n",
    "    )\n",
    "\n",
    "    # We use Optax's \"masking\" functionality to not apply weight decay\n",
    "    # to bias and LayerNorm scale parameters. decay_mask_fn returns a\n",
    "    # mask boolean with the same structure as the parameters.\n",
    "    # The mask is True for parameters that should be decayed.\n",
    "    def decay_mask_fn(params):\n",
    "        flat_params = traverse_util.flatten_dict(params)\n",
    "        flat_mask = {path: (path[-1] != \"bias\" and path[-2:] != (\"LayerNorm\", \"scale\")) for path in flat_params}\n",
    "        return traverse_util.unflatten_dict(flat_mask)\n",
    "\n",
    "    # create adam optimizer\n",
    "    adamw = optax.adamw(\n",
    "        learning_rate=linear_decay_lr_schedule_fn,\n",
    "        b1=training_args.adam_beta1,\n",
    "        b2=training_args.adam_beta2,\n",
    "        eps=training_args.adam_epsilon,\n",
    "        weight_decay=training_args.weight_decay,\n",
    "        mask=decay_mask_fn,\n",
    "    )\n",
    "\n",
    "    # Setup train state\n",
    "    state = TrainState.create(apply_fn=model.__call__, params=model.params, tx=adamw, dropout_rng=dropout_rng)\n",
    "\n",
    "    def cross_entropy(logits, axis):\n",
    "        logprobs = jax.nn.log_softmax(logits, axis=axis)\n",
    "        nll = jnp.diag(logprobs)\n",
    "        ce = -jnp.mean(nll)\n",
    "        return ce\n",
    "\n",
    "    def clip_loss(similarity):\n",
    "        loss = (cross_entropy(similarity, axis=0) + cross_entropy(similarity, axis=1)) / 2\n",
    "        return loss\n",
    "\n",
    "    # Define gradient update step fn\n",
    "    def train_step(state, batch):\n",
    "        dropout_rng, new_dropout_rng = jax.random.split(state.dropout_rng)\n",
    "\n",
    "        def compute_loss(params):\n",
    "            logits = state.apply_fn(**batch, params=params, dropout_rng=dropout_rng, train=True)[0]\n",
    "            loss = clip_loss(logits)\n",
    "            return loss\n",
    "\n",
    "        grad_fn = jax.value_and_grad(compute_loss)\n",
    "        loss, grad = grad_fn(state.params)\n",
    "        grad = jax.lax.pmean(grad, \"batch\")\n",
    "\n",
    "        new_state = state.apply_gradients(grads=grad, dropout_rng=new_dropout_rng)\n",
    "\n",
    "        metrics = {\"loss\": loss, \"learning_rate\": linear_decay_lr_schedule_fn(state.step)}\n",
    "        metrics = jax.lax.pmean(metrics, axis_name=\"batch\")\n",
    "\n",
    "        return new_state, metrics\n",
    "\n",
    "    # Define eval fn\n",
    "    def eval_step(params, batch):\n",
    "        logits = model(**batch, params=params, train=False)[0]\n",
    "        loss = clip_loss(logits)\n",
    "\n",
    "        # summarize metrics\n",
    "        metrics = {\"loss\": loss}\n",
    "        metrics = jax.lax.pmean(metrics, axis_name=\"batch\")\n",
    "        return metrics\n",
    "\n",
    "    # Create parallel version of the train and eval step\n",
    "    p_train_step = jax.pmap(train_step, \"batch\", donate_argnums=(0,))\n",
    "    p_eval_step = jax.pmap(eval_step, \"batch\")\n",
    "\n",
    "    # Replicate the train state on each device\n",
    "    state = state.replicate()\n",
    "\n",
    "    logger.info(\"***** Running training *****\")\n",
    "    logger.info(f\"  Num examples = {len(train_dataset)}\")\n",
    "    logger.info(f\"  Num Epochs = {num_epochs}\")\n",
    "    logger.info(f\"  Instantaneous batch size per device = {training_args.per_device_train_batch_size}\")\n",
    "    logger.info(f\"  Total train batch size (w. parallel & distributed) = {train_batch_size}\")\n",
    "    logger.info(f\"  Total optimization steps = {total_train_steps}\")\n",
    "\n",
    "    #     preprocess = _transform(224)\n",
    "    preprocess = Transform(224)\n",
    "    preprocess = torch.jit.script(preprocess)\n",
    "\n",
    "    train_time = 0\n",
    "    epochs = tqdm(range(num_epochs), desc=f\"Epoch ... (1/{num_epochs})\", position=0)\n",
    "    for epoch in epochs:\n",
    "        # ======================== Training ================================\n",
    "        train_start = time.time()\n",
    "\n",
    "        # Create sampling rng\n",
    "        rng, input_rng = jax.random.split(rng)\n",
    "        train_metrics = []\n",
    "\n",
    "        # Generate an epoch by shuffling sampling indices from the train dataset\n",
    "        train_iter = data_loader(input_rng, train_dataset, preprocess, train_batch_size, shuffle=False)\n",
    "        train_loader = prefetch_to_device(train_iter, size=2, devices=jax.local_devices())\n",
    "        steps_per_epoch = len(train_dataset) // train_batch_size\n",
    "        # train\n",
    "        for _ in tqdm(range(steps_per_epoch), desc=\"Training...\", position=1, leave=False):\n",
    "            batch = next(train_loader)\n",
    "            state, train_metric = p_train_step(state, batch)\n",
    "            train_metrics.append(train_metric)\n",
    "\n",
    "        train_time += time.time() - train_start\n",
    "\n",
    "        train_metric = unreplicate(train_metric)\n",
    "        train_metric = get_metrics(train_metrics)\n",
    "        train_metric = jax.tree_map(jnp.mean, train_metric)\n",
    "\n",
    "        epochs.write(\n",
    "            f\"Epoch... ({epoch + 1}/{num_epochs} | Loss: {train_metric['loss']}, Learning Rate: {train_metric['learning_rate']})\"\n",
    "        )\n",
    "\n",
    "        # ======================== Evaluating ==============================\n",
    "        eval_metrics = []\n",
    "        eval_iter = data_loader(input_rng, eval_dataset, preprocess, eval_batch_size)\n",
    "        eval_loader = prefetch_to_device(eval_iter, size=2, devices=jax.local_devices())\n",
    "        eval_steps = len(eval_dataset) // eval_batch_size\n",
    "        for _ in tqdm(range(eval_steps), desc=\"Evaluating...\", position=2, leave=False):\n",
    "            # Model forward\n",
    "            batch = next(eval_loader)\n",
    "            metrics = p_eval_step(state.params, batch)\n",
    "            eval_metrics.append(metrics)\n",
    "\n",
    "        # normalize eval metrics\n",
    "        eval_metrics = get_metrics(eval_metrics)\n",
    "\n",
    "        eval_metrics = jax.tree_map(jnp.mean, eval_metrics)\n",
    "\n",
    "        # Print metrics and update progress bar\n",
    "        desc = f\"Epoch... ({epoch + 1}/{num_epochs} | Eval Loss: {eval_metrics['loss']})\"\n",
    "        epochs.write(desc)\n",
    "        epochs.desc = desc\n",
    "\n",
    "        # Save metrics\n",
    "        if has_tensorboard and jax.process_index() == 0:\n",
    "            cur_step = epoch * (len(train_dataset) // train_batch_size)\n",
    "            write_metric(summary_writer, train_metrics, eval_metrics, train_time, cur_step)\n",
    "\n",
    "    # save last checkpoint\n",
    "    if jax.process_index() == 0:\n",
    "        params = jax.device_get(unreplicate(state.params))\n",
    "        model.save_pretrained(training_args.output_dir, params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade814aa-cab9-4d80-ba2f-0fb103a604bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if __name__ == \"__main__\":\n",
    "#     main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
